{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test implementing basic EMF iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-09-14T22:29:01.877481",
     "start_time": "2016-09-14T22:29:01.872884"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-09-14T22:29:02.110388",
     "start_time": "2016-09-14T22:29:02.106949"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.utils.fixes import expit    \n",
    "from sklearn.utils.extmath import safe_sparse_dot\n",
    "from sklearn import linear_model, datasets, metrics, preprocessing \n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-09-14T22:29:02.263239",
     "start_time": "2016-09-14T22:29:02.260135"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sig_means(x, b, W):\n",
    "    a = safe_sparse_dot(x, W.T) + b\n",
    "    return expit(a, out=a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### use julia data set\n",
    "\n",
    "I don't know how to reproduce their normalization yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-09-14T22:29:06.895589",
     "start_time": "2016-09-14T22:29:02.796266"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('List of arrays in this file: \\n', [u'HDF5.name___X', u'HDF5.name___y'])\n",
      "(60000, 784) (60000,)\n",
      "norm of X  2117.63422548\n"
     ]
    }
   ],
   "source": [
    "hf =  h5py.File('mnist.h5','r')\n",
    "print('List of arrays in this file: \\n', hf.keys())\n",
    "X = np.array(hf.get('HDF5.name___X'))\n",
    "Y = np.array(hf.get('HDF5.name___y'))\n",
    "print X.shape, Y.shape\n",
    "hf.close()\n",
    "print \"norm of X \",np.linalg.norm(X,ord=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-09-14T22:24:29.473192",
     "start_time": "2016-09-14T22:24:29.470744"
    }
   },
   "source": [
    "### plot the new mnist data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-09-14T22:35:08.065711",
     "start_time": "2016-09-14T22:35:08.058676"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show(image):\n",
    "    \"\"\"\n",
    "    Render a given numpy.uint8 array of pixel data.\n",
    "    Reshape array, and rotate for display\n",
    "    \"\"\"\n",
    "    square_image = np.rot90(np.reshape(image, [28,28]))\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    imgplot = ax.imshow(square_image, cmap=mpl.cm.Greys)\n",
    "    imgplot.set_interpolation('nearest')\n",
    "    ax.xaxis.set_ticks_position('top')\n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-09-14T22:35:16.694134",
     "start_time": "2016-09-14T22:35:15.942756"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD7CAYAAABKWyniAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAC61JREFUeJzt3U+sZnV9x/H3x5IulAQmRGYahg41TRo3ZGKjG7p4TBMl\n3QxxgZYNmMawKJa0GymbexddtC5I6MKNoBkaSaskCphYscGEsFAIdMqgI5o0Q4syt2rAMDvT+XZx\nD8Nl+tz7PNzn773f9yt5wnnOc88933vmfJ7f75zfOYdUFZJ6ed+qC5C0fAZfasjgSw0ZfKkhgy81\nZPClhpYW/CS3JvlJkp8m+cKy1jutJOeT/EeSf0/y3BrU83CSrSQv7Zh3JMlTSV5J8t0k16xZfRtJ\nXkvy4vC6dYX1HU/ydJIfJTmb5K+G+WuxDcfU9/lh/lK2YZYxjp/kfcBPgT8FfgE8D3ymqn6y8JVP\nKcl/An9cVW+suhaAJH8CXAQeqaqbh3n/APy6qr44fHkeqar71qi+DeCtqnpgFTXtlOQYcKyqziS5\nGngBOAV8ljXYhnvU92mWsA2X1eJ/DPhZVb1aVb8F/pntP3KdhDU69KmqZ4Erv4ROAaeH6dPAbUst\naodd6oPt7bhyVXWhqs4M0xeBc8Bx1mQb7lLfDcPHC9+Gy9rRbwD+e8f713jnj1wXBXwvyfNJPrfq\nYnZxfVVtwfaOA1y/4nrGuSfJmSQPrfJQZKckNwEngR8AR9dtG+6o74fDrIVvw7Vp4dbALVX1EeDP\ngL8curLrbt2ut/4S8KGqOglcANahy3818Bhw79CyXrnNVroNx9S3lG24rOD/HPj9He+PD/PWRlW9\nPvz3l8A32T48WTdbSY7C5WPE/1lxPe9SVb+sd04afRn46CrrSXIV26H6p6p6fJi9NttwXH3L2obL\nCv7zwB8mOZHkd4HPAE8sad0TJXn/8M1Lkg8AnwBeXm1VwPax3s7jvSeAu4bpO4HHr1xgyd5V3xCk\nt32K1W/DrwA/rqoHd8xbp234/+pb1jZcyll92B7OAx5k+8vm4ar6+6WseApJ/oDtVr6Aq4Cvrbq+\nJI8CI+A6YAvYAL4FfAO4EXgVuL2q3lyj+j7O9rHqJeA8cPfbx9MrqO8W4BngLNv/rgXcDzwHfJ0V\nb8M96ruDJWzDpQVf0vrw5J7UkMGXGjL4UkMGX2popuCv+403ksbb91n9aW+8SeKwgbQiVTX2uv9Z\nWvypb7ypqsuvjY2Nd71ft5f1Hd761rm2RdS3l1mCfxBuvJE0hif3pIaummHZqW+82dzcvDx97bXX\nzrDKxRuNRqsuYU/Wt3/rXBsst75ZTu79DvAK2yf3Xmf7Gug/r6pzV/xc7XcdkvYvCbXLyb19t/hV\n9b9J7gGe4p0bb85NWEzSGlj4TTq2+NJq7NXie3JPasjgSw0ZfKkhgy81ZPClhgy+1JDBlxoy+FJD\nBl9qyOBLDRl8qSGDLzVk8KWGDL7UkMGXGprl0VsHQjL2duQ2fBaCxrHFlxoy+FJDBl9qyOBLDRl8\nqSGDLzVk8KWGDv04fnezXsfgdQCHky2+1JDBlxoy+FJDBl9qyOBLDRl8qSGDLzU00zh+kvPAb4BL\nwG+r6mPzKGqeZh2H7n4/v9cBHE6zXsBzCRhV1RvzKEbScsza1c8cfoekJZs1tAV8L8nzST43j4Ik\nLd6sXf1bqur1JB9k+wvgXFU9e+UPbW5uXp4ejUaMRqMZVytpFpnXyZckG8BbVfXAFfPrIJ/g6X5y\nb1YH+d/+oEtCVY3dgffd1U/y/iRXD9MfAD4BvLzf3ydpeWbp6h8Fvpmkht/ztap6aj5lSVqkuXX1\nd13BAe/qz8pDhdl03ndmtZCuvqSDy+BLDRl8qSGDLzVk8KWGDL7UkMGXGvK5+gvm8wBmM+nvd5x/\nf2zxpYYMvtSQwZcaMvhSQwZfasjgSw0ZfKkhx/HXnNcB7M1x/v2xxZcaMvhSQwZfasjgSw0ZfKkh\ngy81ZPClhhzHP+S6XwfgOP94tvhSQwZfasjgSw0ZfKkhgy81ZPClhgy+1NDE4Cd5OMlWkpd2zDuS\n5KkkryT5bpJrFlumVqWqFvrSakzT4n8V+OQV8+4D/q2q/gh4GvjbeRcmaXEmBr+qngXeuGL2KeD0\nMH0auG3OdUlaoP0e419fVVsAVXUBuH5+JUlatHldq7/nwdrm5ubl6dFoxGg0mtNqJe1HpjnBkuQE\n8GRV3Ty8PweMqmoryTHg+1X14V2WLU/iaDervgnoMO+bSaiqsRt42q5+htfbngDuGqbvBB7fd3WS\nlm5ii5/kUWAEXAdsARvAt4BvADcCrwK3V9Wbuyxvi69d2eIvzl4t/lRd/RlXbvAPsVUHd5LO+948\nuvqSDhGDLzVk8KWGDL7UkMGXGjL4UkMGX2rI5+prT+s+Tq/9scWXGjL4UkMGX2rI4EsNGXypIYMv\nNWTwpYYcx2/uoI/Td77ffha2+FJDBl9qyOBLDRl8qSGDLzVk8KWGDL7UkOP4h5zj9BrHFl9qyOBL\nDRl8qSGDLzVk8KWGDL7UkMGXGpoY/CQPJ9lK8tKOeRtJXkvy4vC6dbFlajdJ9nwtWlUt9KXFmKbF\n/yrwyTHzH6iqjwyvf51zXZIWaGLwq+pZ4I0xHx3sS8KkxmY5xr8nyZkkDyW5Zm4VSVq4THMcleQE\n8GRV3Ty8/yDwq6qqJH8H/F5V/cUuy9bGxsbl96PRiNFoNI/axeqvxfc4fH0loarG7iD7Cv60nw2f\nlzvH4hh87Wav4E/b1Q87jumTHNvx2aeAl/dfnqRlm3hbbpJHgRFwXZL/AjaAjyc5CVwCzgN3L7BG\nSXM2VVd/phXY1V8ou/razTy6+pIOEYMvNWTwpYYMvtSQwZcaMvhSQwZfasjn6q/YqsfhJ3Gc/nCy\nxZcaMvhSQwZfasjgSw0ZfKkhgy81ZPClhhzHX7B1H6efZFL9k8b5Z/37vY5gMWzxpYYMvtSQwZca\nMvhSQwZfasjgSw0ZfKkhx/FndNDH6WfV/e8/qGzxpYYMvtSQwZcaMvhSQwZfasjgSw0ZfKmhieP4\nSY4DjwBHgUvAl6vqH5McAf4FOAGcB26vqt8ssFY1tO7XCRzU5wVkigcpHAOOVdWZJFcDLwCngM8C\nv66qLyb5AnCkqu4bs3wd1I0zjXXfMbVY67xvJ6Gqxu6gE7v6VXWhqs4M0xeBc8BxtsN/evix08Bt\n8ylX0qK9p2P8JDcBJ4EfAEeragu2vxyA6+ddnKTFmPpa/aGb/xhwb1VdTHJlH2fXPs/m5ubl6dFo\nxGg0em9VSpqricf4AEmuAr4NfKeqHhzmnQNGVbU1nAf4flV9eMyyHuPr0FrnfXumY/zBV4Afvx36\nwRPAXcP0ncDj+65Q0lJNc1b/FuAZ4Czb3fkC7geeA74O3Ai8yvZw3ptjlrfF16G1zvv2Xi3+VF39\nGVd+qIM/iV8Mva1y359HV1/SIWLwpYYMvtSQwZcaMvhSQwZfasjgSw35XP0FW/U1DF5HoHFs8aWG\nDL7UkMGXGjL4UkMGX2rI4EsNGXypIcfxD7lVX0eg9WSLLzVk8KWGDL7UkMGXGjL4UkMGX2rI4EsN\nGXypIYMvNWTwpYYMvtSQwZcaMvhSQwZfamhi8JMcT/J0kh8lOZvk88P8jSSvJXlxeN26+HIlzUMm\n3a+d5BhwrKrOJLkaeAE4BXwaeKuqHpiwfHlPuLR8Saiqsf9jhYkP4qiqC8CFYfpiknPADW//7rlV\nKWlp3tMxfpKbgJPAD4dZ9yQ5k+ShJNfMuTZJCzJ18Idu/mPAvVV1EfgS8KGqOsl2j2DPLr+k9THx\nGB8gyVXAt4HvVNWDYz4/ATxZVTeP+aw2NjYuvx+NRoxGo1lqljSFvY7xpw3+I8Cvqupvdsw7Nhz/\nk+SvgY9W1R1jlvXknrQCMwU/yS3AM8BZoIbX/cAdbB/vXwLOA3dX1daY5Q2+tAIzt/gzrtzgSyuw\nV/C9ck9qyOBLDRl8qSGDLzVk8KWGDL7UkMGXGjL4UkMGX2rI4EsNGXypIYMvNWTwpYYMvtSQwZca\nMvhSQxMfrz0PiU/hltbJwp/AI2n92NWXGjL4UkMGX2rI4EsNGXypof8D2lTiJUzX/xYAAAAASUVO\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x119bbb350>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD7CAYAAABKWyniAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n+FJDBl9q6P8ANPZ2aSBSuCUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x119b77c90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD7CAYAAABKWyniAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAC3RJREFUeJzt3E+sXOV5x/HvL7W6SCwZCwVcYQqNKlXZICtVsnEXE1VK\nUDdGWZCUDURVxKIkqN2Esrl30UWbBRKbbAqJnCqoSpASIFKKUxEJsUhAUBdDHFKpMi0tvk0iqPAu\nKk8X99hc3Ll3hjt/r5/vRxpx5sw9cx5ez2/e9z1nzklVIamXD626AEnLZ/Clhgy+1JDBlxoy+FJD\nBl9qaGnBT3J7kp8n+UWSry5rv9NKciHJvyT55yTPr0E9jybZSvLyjnVHk5xJ8lqSp5McWbP6NpK8\nkeSl4XH7Cus7nuSZJK8mOZfkK8P6tWjDMfV9eVi/lDbMMs7jJ/kQ8Avgj4H/Al4AvlBVP1/4zqeU\n5N+AP6yqt1ZdC0CSPwIuAd+qqtuGdX8L/LqqvjZ8eR6tqgfWqL4N4J2qemgVNe2U5BhwrKrOJjkM\nvAicAr7IGrThHvV9niW04bJ6/E8B/1pVr1fVb4B/YPt/cp2ENZr6VNVzwNVfQqeA08PyaeCOpRa1\nwy71wXY7rlxVXayqs8PyJeA8cJw1acNd6rtpeHnhbbisD/pNwH/seP4G7/1ProsCfpTkhSRfWnUx\nu7ihqrZg+4MD3LDiesa5L8nZJI+sciqyU5JbgRPAT4Ab160Nd9T302HVwttwbXq4NXCyqj4B/Anw\n58NQdt2t2++tvw58rKpOABeBdRjyHwYeB+4fetar22ylbTimvqW04bKC/5/A7+54fnxYtzaq6s3h\nv78Evsf29GTdbCW5Ea7MEf97xfW8T1X9st47aPR3wCdXWU+SQ2yH6u+r6olh9dq04bj6ltWGywr+\nC8DvJ7klyW8DXwCeXNK+J0ry4eGblyQfAT4DvLLaqoDtud7O+d6TwD3D8t3AE1dvsGTvq28I0mWf\nY/Vt+A3gZ1X18I5169SG/6++ZbXhUo7qw/bpPOBhtr9sHq2qv1nKjqeQ5PfY7uULOAR8e9X1JXkM\nGAHXA1vABvB94LvAzcDrwJ1V9fYa1fdptueq7wIXgHsvz6dXUN9J4FngHNv/rgU8CDwPfIcVt+Ee\n9d3FEtpwacGXtD48uCc1ZPClhgy+1JDBlxqaKfjrfuGNpPH2fVR/2gtvknjaQFqRqhr7u/9Zevyp\nL7ypqiuPjY2N9z1ft4f1Xbv1rXNti6hvL7ME/yBceCNpDA/uSQ0dmmHbqS+82dzcvLJ83XXXzbDL\nxRuNRqsuYU/Wt3/rXBsst75ZDu79FvAa2wf33mT7N9B/WlXnr/q72u8+JO1fEmqXg3v77vGr6n+T\n3Aec4b0Lb85P2EzSGlj4RTr2+NJq7NXje3BPasjgSw0ZfKkhgy81ZPClhgy+1JDBlxoy+FJDBl9q\nyOBLDRl8qSGDLzVk8KWGDL7UkMGXGprl1lvSzJKxl4vPjfeCGM8eX2rI4EsNGXypIYMvNWTwpYYM\nvtSQwZcaMvhSQwZfasjgSw0ZfKkhgy81ZPClhgy+1JDBlxqa6Xr8JBeA/wHeBX5TVZ+aR1GSFmvW\nG3G8C4yq6q15FCNpOWYd6mcO7yFpyWYNbQE/SvJCki/NoyBJizfrUP9kVb2Z5KNsfwGcr6rnrv6j\nzc3NK8uj0YjRaDTjbiXNIvO6GWGSDeCdqnroqvXlDQ+1G2+2uThJqKqxDbzvoX6SDyc5PCx/BPgM\n8Mp+30/S8swy1L8R+F6SGt7n21V1Zj5lSVqkuQ31d92BQ33twaH+4ixkqC/p4DL4UkMGX2rI4EsN\nGXypIYMvNWTwpYYMvtSQwZcaMvhSQwZfasjgSw0ZfKkhgy81ZPClhgy+1JDBlxoy+FJDBl9qyOBL\nDRl8qSGDLzVk8KWGDL7UkMGXGjL4UkMGX2rI4EsNGXypIYMvNWTwpYYmBj/Jo0m2kry8Y93RJGeS\nvJbk6SRHFlumpHmapsf/JvDZq9Y9APxTVf0B8AzwV/MuTNLiTAx+VT0HvHXV6lPA6WH5NHDHnOuS\ntED7nePfUFVbAFV1EbhhfiVJWrRDc3qf2uvFzc3NK8uj0YjRaDSn3Uraj1TtmdntP0puAZ6qqtuG\n5+eBUVVtJTkG/LiqPr7LtjXNPtRTkoW+f+fPXhKqamwDTzvUz/C47EngnmH5buCJfVcnaekm9vhJ\nHgNGwPXAFrABfB/4LnAz8DpwZ1W9vcv29vjalT3+4uzV40811J9x5ysN/qI/WOtu3T/4Bn9x5jHU\nl3QNMfhSQwZfasjgSw0ZfKkhgy81ZPClhub1W/2V6X6efhLbR+PY40sNGXypIYMvNWTwpYYMvtSQ\nwZcaMvhSQwf+PP6iLeF+BQt9/+4mtW/X6/Xt8aWGDL7UkMGXGjL4UkMGX2rI4EsNGXypIc/jr9hB\nP4/s7xAOJnt8qSGDLzVk8KWGDL7UkMGXGjL4UkMGX2poYvCTPJpkK8nLO9ZtJHkjyUvD4/bFlql1\nVVULfSxakj0f16ppevxvAp8ds/6hqvrE8PjHOdclaYEmBr+qngPeGvPStft1KF3jZpnj35fkbJJH\nkhyZW0WSFi7TzKOS3AI8VVW3Dc8/CvyqqirJXwO/U1V/tsu2tbGxceX5aDRiNBrNo/bL7z+39xrn\noP+W/qBb9Tz7IP/7J6GqxjbgvoI/7WvD67XIxjP41zaDv397BX/aoX7YMadPcmzHa58DXtl/eZKW\nbeJluUkeA0bA9Un+HdgAPp3kBPAucAG4d4E1SpqzqYb6M+3Aob5m4FB//+Yx1Jd0DTH4UkMGX2rI\n4EsNGXypIYMvNWTwpYa8r77W2qTz6Ks+z39Q2eNLDRl8qSGDLzVk8KWGDL7UkMGXGjL4UkMH/jy+\n53mlD84eX2rI4EsNGXypIYMvNWTwpYYMvtSQwZcaMvhSQwZfasjgSw0ZfKkhgy81ZPClhgy+1JDB\nlxqaGPwkx5M8k+TVJOeSfGVYfzTJmSSvJXk6yZHFlystV5I9HwdVpriRxTHgWFWdTXIYeBE4BXwR\n+HVVfS3JV4GjVfXAmO1r0j4WadZ/nFXWrslWHb51/nwkoarGNtDEHr+qLlbV2WH5EnAeOM52+E8P\nf3YauGM+5UpatA80x09yK3AC+AlwY1VtwfaXA3DDvIuTtBhT33NvGOY/DtxfVZeSXD3G2XXMs7m5\neWV5NBoxGo0+WJWS5mriHB8gySHgB8APq+rhYd15YFRVW8NxgB9X1cfHbOscXwvjHH93M83xB98A\nfnY59IMngXuG5buBJ/ZdoaSlmuao/kngWeAc28P5Ah4Enge+A9wMvA7cWVVvj9neHl8LY4+/u716\n/KmG+jPu3OBrZRb9xbDOn495DPUlXUMMvtSQwZcaMvhSQwZfasjgSw0ZfKmhqX+rf1Ct83lWaVXs\n8aWGDL7UkMGXGjL4UkMGX2rI4EsNGXypoWv+PL5683cc49njSw0ZfKkhgy81ZPClhgy+1JDBlxoy\n+FJDBl9qyOBLDRl8qSGDLzVk8KWGDL7UkMGXGpoY/CTHkzyT5NUk55J8eVi/keSNJC8Nj9sXX66k\necik65WTHAOOVdXZJIeBF4FTwOeBd6rqoQnbl9dES8uXhKrKuNcm3oijqi4CF4flS0nOAzddfu+5\nVSlpaT7QHD/JrcAJ4KfDqvuSnE3ySJIjc65N0oJMHfxhmP84cH9VXQK+Dnysqk6wPSLYc8gvaX1M\nnOMDJDkE/AD4YVU9POb1W4Cnquq2Ma/VxsbGleej0YjRaDRLzZKmsNccf9rgfwv4VVX95Y51x4b5\nP0n+AvhkVd01ZlsP7kkrMFPwk5wEngXOATU8HgTuYnu+/y5wAbi3qrbGbG/wpRWYucefcecGX1qB\nvYLvL/ekhgy+1JDBlxoy+FJDBl9qyOBLDRl8qSGDLzVk8KWGDL7UkMGXGjL4UkMGX2rI4EsNGXyp\nIYMvNTTx9trzkHgXbmmdLPwOPJLWj0N9qSGDLzVk8KWGDL7UkMGXGvo/t6WN6kVvN4QAAAAASUVO\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x119d09fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD7CAYAAABKWyniAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x119b11cd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD7CAYAAABKWyniAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDRl8qSGDLzX0f9KRhPnmW81QAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x118c9f990>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    show(X[i,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-09-14T22:30:01.920393",
     "start_time": "2016-09-14T22:30:01.916657"
    }
   },
   "source": [
    "Notice that the images are binary now, not greyscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-08-30T14:00:33.306668",
     "start_time": "2016-08-30T14:00:33.304102"
    }
   },
   "source": [
    "### Implement RBM and Test\n",
    "\n",
    "Eventually need to convert to sklearn code\n",
    "\n",
    "Using as much as existing RBM code as I can now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-09-05T00:00:28.751727",
     "start_time": "2016-09-05T00:00:28.745132"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.externals.six.moves import xrange\n",
    "from sklearn.utils import check_array\n",
    "from sklearn.utils import check_random_state\n",
    "from sklearn.utils import gen_even_slices\n",
    "from sklearn.utils import issparse\n",
    "from sklearn.utils.extmath import safe_sparse_dot\n",
    "from sklearn.utils.extmath import log_logistic\n",
    "from sklearn.utils.fixes import expit             # logistic function\n",
    "from sklearn.utils.validation import check_is_fitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-09-05T00:00:28.760280",
     "start_time": "2016-09-05T00:00:28.753677"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_v_bias(X):\n",
    "    # If the user specifies the training dataset, it can be useful to                                                                                   \n",
    "    # initialize the visibile biases according to the empirical expected                                                                                \n",
    "    # feature values of the training data.                                                                                                              \n",
    "    #                                                                                                                                                   \n",
    "    # TODO: Generalize this biasing. Currently, the biasing is only written for                                                                         \n",
    "    #       the case of binary RBMs.\n",
    "    eps = 1e-8\n",
    "\n",
    "    probVis = np.mean(X,axis=0)             # Mean across  samples    \n",
    "    probVis[probVis < eps] = eps            # Some regularization (avoid Inf/NaN)  \n",
    "    print np.linalg.norm(probVis)\n",
    "\n",
    "    #probVis[probVis < (1.0-eps)] = (1.0-eps)   \n",
    "    v_bias = np.log(probVis / (1.0-probVis)) # Biasing as the log-proportion  \n",
    "    return v_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-09-05T00:00:28.802438",
     "start_time": "2016-09-05T00:00:28.762628"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class EMF_RBM():\n",
    "    def __init__(self, n_components=256, learning_rate=0.005, batch_size=100,\n",
    "                 n_iter=20, verbose=0, random_state=None, momentum = 0.5, decay = 0.01, weight_decay='L1'):\n",
    "        self.n_components = n_components\n",
    "        self.learning_rate = learning_rate\n",
    "        self.batch_size = batch_size\n",
    "        self.n_iter = n_iter\n",
    "        self.verbose = verbose\n",
    "        \n",
    "        self.momentum = momentum\n",
    "        self.decay = decay\n",
    "        self.weight_decay = weight_decay\n",
    "            \n",
    "        \n",
    "        # self.random_state_ = random_state\n",
    "        # always start with new random state\n",
    "        self.rng = check_random_state(random_state)\n",
    "        \n",
    "        # initialize arrays to 0\n",
    "        self.W = np.asarray(\n",
    "            self.rng.normal(\n",
    "                0,\n",
    "                0.001,\n",
    "                (self.n_components, X.shape[1])\n",
    "            ),\n",
    "            order='fortran')\n",
    "        \n",
    "        self.dW_prev = np.zeros_like(self.W)\n",
    "        self.W2 = self.W*self.W\n",
    "\n",
    "\n",
    "        self.h_bias = np.zeros(self.n_components, )\n",
    "        #self.v_bias = np.zeros(X.shape[1], )\n",
    "        self.h_samples_ = np.zeros((self.batch_size, self.n_components))\n",
    "        \n",
    "        # learning rate / mini_batch\n",
    "        self.lr = 0.0\n",
    "        \n",
    "        print \"W norm \", np.linalg.norm(self.W, ord=2)\n",
    "        \n",
    "        # init vbias\n",
    "        self.v_bias = init_v_bias(X)\n",
    "        print \"v bias  \",self.v_bias.shape\n",
    "\n",
    "        print \"v bias norm \", np.linalg.norm(self.v_bias, ord=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-09-05T00:00:28.808961",
     "start_time": "2016-09-05T00:00:28.804760"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sample_layer(rbm, layer):\n",
    "    return (rbm.rng.random_sample(size=l.shape) < layer)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-09-05T00:00:28.815103",
     "start_time": "2016-09-05T00:00:28.811310"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _sample_hiddens(rbm, v):\n",
    "    return sample_layer(rbm, _mean_hiddens(rbm, v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-09-05T00:00:28.821949",
     "start_time": "2016-09-05T00:00:28.817476"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _mean_hiddens(rbm, v):\n",
    "    p = safe_sparse_dot(v, rbm.W.T) + rbm.h_bias\n",
    "    return expit(p, out=p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-09-05T00:00:28.830168",
     "start_time": "2016-09-05T00:00:28.825374"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _mean_visibles(rbm, h):\n",
    "    p = np.dot(h, rbm.W) + rbm.v_bias\n",
    "    return expit(p, out=p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-09-05T00:00:28.837142",
     "start_time": "2016-09-05T00:00:28.833546"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _sample_visibles(rbm, h):\n",
    "    return sample_layer(rbm, _mean_visible(rbm, h))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-09-02T19:24:39.829999",
     "start_time": "2016-09-02T19:24:39.826110"
    },
    "collapsed": true
   },
   "source": [
    "def sample_visibles(rbm, h):\n",
    "    p = np.dot(h, rbm.W)\n",
    "    p += rbm.v_bias\n",
    "    expit(p, out=p)\n",
    "    return (rbm.rng.random_sample(size=p.shape) < p), p"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-09-02T20:12:06.667567",
     "start_time": "2016-09-02T20:12:06.663179"
    },
    "collapsed": true
   },
   "source": [
    "def sample_hiddens(rbm, v):\n",
    "    p = _mean_hiddens(rbm, v)\n",
    "    return (rbm.rng.random_sample(size=p.shape) < p), p "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-09-02T19:24:40.295848",
     "start_time": "2016-09-02T19:24:40.292563"
    },
    "collapsed": true
   },
   "source": [
    "def gibbs_simple(rbm, v):\n",
    "    h_ = _sample_hiddens(rbm, v)\n",
    "    v_ = _sample_visibles(rbm, h_)\n",
    "    return v_"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-09-02T19:24:41.043974",
     "start_time": "2016-09-02T19:24:41.034838"
    },
    "collapsed": false
   },
   "source": [
    "# uses sample_x(), not _sample_x()\n",
    "# quite different from simple\n",
    "# we return all samples, where as before we just sampled the visible\n",
    "# and the h we return is the mean, not the sample\n",
    "def gibbs(rbm, vis, n_times=1):\n",
    "    v_pos = vis\n",
    "    h_samp, h_pos = sample_hiddens(rbm, v_pos)\n",
    "    h_neg = np.zeros_like(h_pos)\n",
    "    v_neg = np.zeros_like(v_pos)\n",
    "            \n",
    "    if (n_times > 0):               \n",
    "        v_neg = _sample_visibles(rbm, h_samp)\n",
    "        h_samp, h_neg = sample_hiddens(rbm, v_neg)\n",
    "        \n",
    "        for i in range(n_times-1):\n",
    "            v_neg = sample_visibles(rbm, h_samp)\n",
    "            h_samp, h_neg = sample_hiddens(rbm, v_neg)\n",
    "        end\n",
    "    end\n",
    "    return v_pos, h_pos, v_neg, h_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-09-05T00:00:28.844646",
     "start_time": "2016-09-05T00:00:28.839172"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# init starts with samples = [0] :| ?\n",
    "def init_batch(rbm, vis):\n",
    "    v_pos = vis\n",
    "    v_init = v_pos\n",
    "    \n",
    "    h_pos = _mean_hiddens(rbm, v_pos)\n",
    "    h_init = h_pos\n",
    "   \n",
    "    return v_pos, h_pos, v_init, h_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-09-05T00:00:28.857360",
     "start_time": "2016-09-05T00:00:28.846715"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def fit(rbm, X):\n",
    "    \n",
    "    n_samples = X.shape[0]\n",
    "    n_batches = int(np.ceil(float(n_samples) / rbm.batch_size))\n",
    "    \n",
    "    print \"fitting with n_batches = \",n_batches, \" in \",rbm.n_iter, \"iterations\"\n",
    "    \n",
    "    batch_slices = list(gen_even_slices(n_batches * rbm.batch_size,\n",
    "                                        n_batches, n_samples))\n",
    "    for iter in xrange(1, rbm.n_iter + 1):\n",
    "        for batch_slice in batch_slices:\n",
    "            fit_batch(rbm, X[batch_slice])\n",
    "\n",
    "        print iter , \" . \" ,\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### run an RBM right here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-09-05T00:00:28.866558",
     "start_time": "2016-09-05T00:00:28.859717"
    },
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def equilibrate(rbm, v0, h0, iters=5):\n",
    "    mv = v0\n",
    "    mh = h0\n",
    "    for i in range(iters):\n",
    "        mv = 0.5 *mv_update(rbm, mv, mh) + 0.5*mv\n",
    "        mh = 0.5 *mh_update(rbm, mv, mh) + 0.5*mh\n",
    "\n",
    "    return mv, mh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-09-05T00:00:28.874458",
     "start_time": "2016-09-05T00:00:28.868908"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mv_update(rbm, v, h):  \n",
    "    a = np.dot(h, rbm.W) + rbm.v_bias\n",
    "\n",
    "    h_fluc = h-(h*h)\n",
    "    a += h_fluc.dot(rbm.W2)*(0.5-v)\n",
    "    \n",
    "    return expit(a, out=a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-09-05T00:00:28.881554",
     "start_time": "2016-09-05T00:00:28.876460"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mh_update(W2, v, h):\n",
    "    a = safe_sparse_dot(v, rbm.W.T) + rbm.h_bias\n",
    "    \n",
    "    v_fluc = v-(v*v)\n",
    "    a += v_fluc.dot(rbm.W2.T)*(0.5-h)\n",
    "\n",
    "    return expit(a, out=a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-09-05T00:00:28.891953",
     "start_time": "2016-09-05T00:00:28.884046"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def weight_gradient(rbm, v_pos, h_pos ,v_neg, h_neg):\n",
    "    # naive  / mean field\n",
    "    dW = safe_sparse_dot(v_pos.T, h_pos, dense_output=True).T - np.dot(h_neg.T, v_neg)\n",
    "    \n",
    "    #print \"dW naive\", np.linalg.norm(dW, ord=2)\n",
    "    # tap2 correction\n",
    "    h_fluc = (h_neg - (h_neg*h_neg)).T\n",
    "    v_fluc = (v_neg - (v_neg*v_neg))\n",
    "    dW -= h_fluc.dot(v_fluc)*rbm.W\n",
    "\n",
    "    return dW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-09-05T00:00:28.927647",
     "start_time": "2016-09-05T00:00:28.893817"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def fit_batch(rbm, X_batch):    \n",
    " \n",
    "    lr = float(rbm.learning_rate) / X_batch.shape[0]\n",
    "    decay = rbm.decay\n",
    "    \n",
    "    #print \"W, hb vb norm \", np.linalg.norm(rbm.W, ord=2), np.linalg.norm(rbm.h_bias, ord=2), np.linalg.norm(rbm.v_bias, ord=2)\n",
    "    #print \"batch norm \", np.linalg.norm(X_batch, ord=2)\n",
    "    \n",
    "    v_pos, h_pos, v_init, h_init = init_batch(rbm, X_batch)\n",
    " \n",
    "    #print \"v, h init norm \", np.linalg.norm(v_init, ord=2), np.linalg.norm(h_init, ord=2)\n",
    "    #print \"vb norm \"\n",
    "\n",
    "\n",
    "    # get_negative_samples\n",
    "    v_neg, h_neg = equilibrate(rbm, v_init, h_init) \n",
    "    #print \"v, h neg norm \", np.linalg.norm(v_neg, ord=2), np.linalg.norm(h_neg, ord=2)\n",
    "\n",
    "    # basic gradient\n",
    "    dW = weight_gradient(rbm, v_pos, h_pos ,v_neg, h_neg) \n",
    "    \n",
    "    #print \"dW norm \", np.linalg.norm(dW, ord=2)\n",
    "\n",
    "\n",
    "    # regularization based on weight decay\n",
    "    #  similar to momentum >\n",
    "    if rbm.weight_decay == \"L2\":\n",
    "        dW += decay * np.sign(rbm.W)\n",
    "    elif rbm.weight_decay == \"L1\":\n",
    "        dW += decay * rbm.W\n",
    "\n",
    "    # can we use BLAS here ?\n",
    "    # momentum\n",
    "    # note:  what do we do if lr changes per step ?    \n",
    "    dW = rbm.momentum * rbm.dW_prev  \n",
    "    rbm.W += lr * dW  \n",
    "    \n",
    "    # for next iteration\n",
    "    rbm.dW_prev =  dW  \n",
    "    rbm.W2 = rbm.W*rbm.W\n",
    "    \n",
    "    # update bias terms\n",
    "    rbm.h_bias += lr * (h_pos.sum(axis=0) - h_neg.sum(axis=0))\n",
    "    rbm.v_bias += lr * (np.asarray(v_pos.sum(axis=0)).squeeze() - v_neg.sum(axis=0))\n",
    "\n",
    "    # only resample (binomial) for CD\n",
    "    # h_neg[rbm.rng.uniform(size=h_neg.shape) < h_neg] = 1.0  \n",
    "    # rbm.h_samples_ = np.floor(h_neg, h_neg)\n",
    "        \n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-09-05T00:00:29.007181",
     "start_time": "2016-09-05T00:00:28.929808"
    },
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W norm  0.0438319055922\n",
      "8.42502854466\n",
      "v bias   (784,)\n",
      "v bias norm  195.421791256\n"
     ]
    }
   ],
   "source": [
    "rbm = EMF_RBM(momentum=0.5, decay=0.01, learning_rate=0.005, n_iter=20)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-09-04T23:28:03.944844",
     "start_time": "2016-09-04T23:28:03.918453"
    },
    "collapsed": false,
    "scrolled": false
   },
   "source": [
    "fit_batch(rbm, X[0:100])            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-09-05T00:05:55.912460",
     "start_time": "2016-09-05T00:00:30.660696"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting with n_batches =  600  in  20 iterations\n",
      "1  .  2  .  3  .  4  .  5  .  6  .  7  .  8  .  9  .  10  .  11  .  12  .  13  .  14  .  15  .  16  .  17  .  18  .  19  .  20  . \n"
     ]
    }
   ],
   "source": [
    "fit(rbm, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### try classifier\n",
    "\n",
    "#### should we be using the EMF estimator?\n",
    "\n",
    "what are the correlations...do they drop to 0 as we converge ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-09-05T00:26:34.455630",
     "start_time": "2016-09-05T00:26:34.452408"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model, datasets, metrics, preprocessing \n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-09-05T00:26:35.158747",
     "start_time": "2016-09-05T00:26:34.619915"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p = sig_means(X, rbm.h_bias , rbm.W)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-09-05T00:26:35.165119",
     "start_time": "2016-09-05T00:26:35.160605"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 256) (60000,)\n"
     ]
    }
   ],
   "source": [
    "print p.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-09-05T00:26:35.234387",
     "start_time": "2016-09-05T00:26:35.166771"
    },
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(p, Y, test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-09-05T00:27:12.888431",
     "start_time": "2016-09-05T00:26:35.236960"
    },
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000 0.903833333333\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for c in [5000]:\n",
    "    lr  = linear_model.LogisticRegression()\n",
    "    lr.C = c\n",
    "    lr.fit(X_train, Y_train)\n",
    "    Y_test_pred = lr.predict(X_test)\n",
    "    acc = accuracy_score(Y_test, Y_test_pred)\n",
    "\n",
    "    print c, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-09-05T00:27:12.893304",
     "start_time": "2016-09-05T00:27:12.890460"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### note bad, but not great"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
